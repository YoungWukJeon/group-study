# 저장소와 검색 
  
가장 기본적인 수준에서 데이터 베이스는 2 가지 작업을 수행함 
- 데이터를 저장
- 저장한 데이터를 요청하면 데이터를 제공 
  
이번장에서는 데이터 베이스가 데이터를 **저장**과 **검색** 처리하는 방법을 알아본다  
  
애플리케이션 개발자는 자신의 저장소 엔진을 구현하기 보다는 사용 가능한 여러 저장소 엔진 중에서 애플리케이션에 적합한 엔진을 선택하는 작업이 필요함   
특정 작업부하(workload) 유형에서 좋은 성능을 내는 저장소 엔진 선택하고 사용하기 위해서는 **저장소 내부에서 수행되는 작업에 대한 대략적인 개념을 이해할 필요가 있음** 
  
## 데이터 베이스를 강력하게 만드는 데이터 구조 
세상에서 가장 간단한 데이터 베이스
```shell script
#!/bin/bash 

db_set() {
    echo "$1,$2" >> database
}

db_get() {
    grep "^$1," database | sed -e "s/^$1,//" | tail -n 1
}
```
key-value 저장소 함수를 2개로 구현했다 
- db_set 함수 
    * key, value 파라미터를 입력받아 ```,```를 구분자로 사용해 database 파일에 append 한다 
- db_get 함수
    * key 를 입력받아 database 에서 line 을 추출하고 key + ```,``` 를 제거 한 뒤 가장 마지막 line 1개만 출력 
    * db_set 에서 데이터를 append 하기 때문에 마지막 값을 출력하려면 가장 마지막 라인을 출력해야 한다 
  
실행 예제 
```shell script
$ db_set 123456 '{"name":"London","attractiions":["Big Ben","London Eye"]}'
$ db_set 42 '{"name":"San Francisco","attractiions":["Golden Gate Bridge"]}'

$ db_get 42
{"name":"San Francisco","attractiions":["Golden Gate Bridge"]}

$ db_set 42 '{"name":"San Francisco","attractiions":["Exploratorium"]}'
$ db_get 42
{"name":"San Francisco","attractiions":["Exploratorium"]}

$ cat database
123456,{"name":"London","attractiions":["Big Ben","London Eye"]}
42,{"name":"San Francisco","attractiions":["Golden Gate Bridge"]}
42,{"name":"San Francisco","attractiions":["Exploratorium"]}
```

db_set 함수는 매우 간단한 작업의 경우에는 꽤 좋은 성능을 보여준다  
실제로 많은 데이터베이스는 내부적으로 추가 전용(append-only) 데이터 파일인 **로그(log)** 를 사용한다  
- 실제 데이터베이스는 처리해야할 여러가지 문제들이 있지만 기본 원리는 같음 
- 여러가지 문제 = 동시성 제어, 디스크 공간 회수, 오류 처리, 부분적으로 기록된 레코드 처리 

> **로그** 라는 단어는 애플리케이션 로그를 언급할때 종종 사용되기도 하는데  
> 이 책에서는 조금 더 일반적인 의미로 연속된 추가 전용 레코드의 의미로 **로그** 라는 단어를 사용한다 
  
반면에 db_get 함수는 많은 레코드가 있으면 성능이 매우 좋지 않다  
key 로 value 를 찾기 위해서 모든 레코드를 탐색하기 때문에 검색 비용이 ```O(n)``` 이다  

데이터베이스에서 key 로 value 을 효율적으로 찾기 위해서는 다른 데이터 구조가 필요한데 바로 **색인** 이다  
**색인**은 어떤 **부가적인 메타 데이터**를 이용해서 데이터의 위치를 찾는것이다  
  
색인은 기본 데이터에서 파생된 **추가적인 구조** 이다  
- 이런 추가적인 구조는 일반적으로 쓰기 작업에서 오버헤드가 발생함 
    * 데이터를 쓸 때마다 매번 색인도 함께 갱신되어야 함 
- 하지만 색인을 잘 선택했다면 읽기 속도는 향상된다 
> 이것은 저장소 시스템에서 중요한 트레이드 오프다

## 해시 색인 
키-값 데이터를 색인해보자  
키-값 저장소는 대부분의 프로그래밍 언어에서 볼 수 있는 사전 타입(dictionary type) 과 매우 유사하다  
  
앞의 예제처럼 단순히 파일에 추가하는 방식으로 데이터 저장소를 구성한다고 가정해보자.  
가장 간단하게 사용할 수 있는 색인 전략은 인메모리 해시 맵에 각 key 의 byte offset 을 매핑해 두는 것이다  
![in_memeory_hashmap](images/3.1_in_memory_hashmap.jpeg)  
그림 3-1 에서 보는 것 처럼 새로운 키-값이 파일에 추가 될 때마다 해시맵에도 기록하고 검색시에는 해시 맵에서 key 를 이용해 바이트 오프셋을 찾아서 해당 위치를 구하고 값을 읽는다  
  
이 방식은 매우 단순해 보이지만 실제로 많이 사용하는 접근법이다  
대표적으로 비트캐스크(Bitcask)(리악(Riak)의 기본저장소 엔진) 가 있다  
비트캐스크는 해시맵을 전부 메모리에 유지하기 때문에 모든 키가 램(RAM)에 저장된다는 전제로 고성능으로 읽기, 쓰기를 보장한다  
값을 한번의 디스크 탐색으로 디스크에서 적재(load)할 수 있기 때문에 메모리보다 더 많은 공간을 사용할 수 있다  
그리고 데이터 파일의 일부가 이미 파일 시스템 캐시에 있다면 읽기 작업에서 디스크 입출력이 필요하지 않음  
  
비트 캐스크 같은 저장 소 엔진은 각 키의 값이 자주 갱신되는 상황에 매우 적합하다  
예를들어 key = 고양이 비디오 URL 이고 value = 재생된 횟수 인 경우이다  
이런 경우 key 당 쓰기 수가 많지만 고유 키가 많지 않기 때문에 메모리에 모든 key 를 보관할 수 있다  
  
데이터를 항상 파일에 추가만 한다면 **디스크가 부족**해진다  
이런 문제를 해결하기 위해서 로그를 특정 크기의 **세그먼트**로 나누는 방식이 좋은 해결책이다  
특정 크기에 도달하면 세그먼트 파일을 닫고 새로운 세그먼트 파일에 이후 쓰기를 수행한다  
그리고 디스크가 차는것을 방지하기 위해 세그먼트 파일들에 대해서 컴팩션(compaction)을 수행할 수 있다
-  컴팩션: 중복된 키를 버리고 각 키의 최신 갱신 값만 유지하는 것 
  
![segment_compact](images/3.2_segment_compact.jpeg)  
  
컴팩션은 보통 세그먼트를 더 작게 만들기 때문에 아래 3-3 그림 처럼 여러 세그먼트의 병합도 함께 수행할 수 있다  
![segment_compact_and_merge](images/3.3_segment_compact_and_merge.jpeg)   
세그먼트는 불면이기 때문에 병합 과정에서 새로운 세그먼트 파일을 생성한다  
읽기 요청이 발생하면 병합이 끝나기 전에서는 이전 세그먼트에서 데이터를 읽고  
병합이 끝난 이후에는 새로운 세그먼트에서 데이터를 읽도록 전환한다  
전환 이후에는 이전 세그먼트 파일들을 삭제하면된다  
  
이제 각 세그먼트는 키를 파일 오프셋에 매핑한 자체 인메모리 해시 테이블을 갖는다  
키의 값을 찾기 위해서 최신 세그먼트 해시 맵을 먼저 확인하고 값이 없다면 두번째 최신 세그먼트 등을 확인해서 값을 찾는다  
병합 과정에서 적은 수의 세그먼트를 유지하기 때문에 많으 해시맵을 확인 할 필요가 없다  
  
위 내용을 실제로 구현하려면 세부적으로 많은 사항을 고려해야 한다 
- 파일 형식
    * CSV 는 로그에 적합한 형식이 아님 
    * 문자열을 부호화하는 바이너리 형식을 사용하는 편이 더 빠르고 간편함 
- 레코드 삭제 
    * 키와 관련된 값을 삭제하려면 데이터 파일에 특수한 삭제 레코드를 추가해야 함 
    * 이런 삭제 레코드를 **툼스톤(tombstone)** 이라고 한다 
    * 로그 세그먼트가 병합될 떄 툼스톤은 병합 과정에서 삭제된 키의 이전 값을 무시하게 함 
- Crash 복구 
    * 데이터베이스가 재시작되면 인메모리 해시 맵은 손실됨 
    * 전체 세그먼트 파일을 처음부터 끝까지 읽어서 해시 맵을 복원할 수 있지만 파일이 크면 매우 오래 걸림 
    * 비트캐스크는 각 세그먼트 해시 맵을 snapshot 을 디스크에 저장함으로써 복구 속도를 높인다 
- 부분적으로 레코드 쓰기
    * 데이터베이스는 로그에 레코드를 추가하는 도중에도 죽을 수 있음 
    * 비트캐스크 파일은 체크섬을 포함하고 있어 로그의 손상된 부분을 무시할 수 있음 
- 동시성 제어 
    * 쓰기를 순차적으로 로그에 추가할 때 일반적인 구현 방법은 1개의 쓰기 스레드만 사용하는 것 
    * 세그먼트는 추가전용 or 불변 이기 때문에 다중 스레드로 동시에 읽을 수 있음 
  
추가 전용 로그는 낭비 처럼 보일 수 있다. 예전 값을 새로운 값으로 덮어 쓰는게 아니라 추가하는 방식을 사용하기 때문에 ..  
하지만 추가 전용 설계는 여러 장점들이 존재한다  
- 추가와 세그먼트 병합은 순차적인 쓰기 작업이기 때문에 무작위 쓰기 보다 훨씬 빠름 
    * 특히 자기 회전 디스크 하드드라이브에서 빠름 
    * 일부 확장된 순차 쓰기는 플래시 기반 솔리드 스테이트 드라이브(SSD)도 선호된다 
- 세그먼트 파일이 추가전용이나 불변이면 **동시성과 crash 복구**가 훨씬 간단하다 
    * 예를들어 값을 덮어쓰는 동안 데이터베이스가 죽는 경우에 대한 걱정 할 필요가 없음 
    * 이전 값 부분과 새로운 값 부분을 포함 파일을 나누어 남겨두기 때문에 
- 오래된 세그먼트 병합은 시간이 지남에 따라 조각화되는 데이터 파일 문제를 피할 수 있음 
  
하지만 해시 테이블 색인도 제한 사항이 있다 
- 해시 테이블은 메모리에 저장해야 하기 때문에 key 가 많으면 문제가 된다 
    * 디스크에 해시 맵을 유지하는 방식은 성능이 매우 나쁘고 해시 충돌 해소를 위한 성가신 로직이 필요함 
- 해시 테이블은 범위 질의(range query)에 효율적이지 않음 
    * kitty0000 ~ kity9999 사이의 모든 레코드를 검색하고 싶을때 해시 맵에서는 모든 키를 조회해야 한다 

## SS 테이블과 LSM 트리 
세그먼트 파일의 형식에 변경사항 한 가지를 적용해보자  
변경 요구사항은 **키로 정렬** 하는 것이다  
  
이 처럼 키로 정렬된 형식을 **정렬된 문자열 테이블(Sorted String Table) 또는 SS테이블** 이라고 부른다  
각 키는 병합된 세그먼트 파일 내에 한 번만 나타나야 한다(컴팩션 과정이 이를 보장)  
SS테이블은 해시 색인을 가진 로그 세그먼트보다 몇 가지 큰 **장점**이 있다
- 세그먼트 병합은 파일이 사용 가능한 메모리 보다 크더라도 간단하고 효율적 
    * 이 접근 법은 병합정렬 알리고림즈에서 사용하는 방식과 유사함 
    * 입력 파일을 함께 읽고 각 파일의 첫 번째 키를 보고 낮은 키를 출력 파일에 기록
    * 같은 키가 존재하면 가장 최근 세그먼트의 값을 출력 파일에 기록 
![ss_table_sgemnt_compant_and_merge](images/3.4_ss_table_sgemnt_compant_and_merge.jpeg)   
- 파일에서 키를 찾기 위해 더는 메모리에 모든 키의 색인을 유지할 필요가 없다 
    * 예를들어 아래 3-5 에서 handiwork 키를 찾는다고 가정한다 
    * handiwork 는 메모리에 있는 색인 정보에 존재하지 않지만 handbag 과 handsome 의 오프셋을 알고 있고 정렬되어 있다 
    * 따라서 handbag 오프셋으로 이동해 handiwork 가 나올 때까지 스캔하면 된다 
    * 일부 키에 대한 오프셋을 알려주는 인메모리 색인이 여전히 필요함 
    * 하지만 색인하는 key 가 적기 때문에 빠르게 스캔할 수 있음 
    * 세그먼트 파일 내 수 킬로바이트 당 하나의 키로 충분함 
> 모든 키와 값이 고정 크기라면 이진 검색을 사용하면 되기 때문에 인메모리 색인을 전혀 사용하지 않을 수 있음 
> 하지만 현식적으로 보통 키-값은 가변길이이므로 색인이 없다면 다음 레코드가 시작하는 부분을 알기 어려움  

![in_memeory_ss_table](images/3.5_in_memeory_ss_table.jpeg)   
- 읽기 요청은 여러 키-값 쌍을 스캔해야 하기 때문에 해당 레코드들을 블록으로 그룹화 해서 디스크 쓰기전에 압축한다. (그림 3-5에 음영부분)
    * 희소 인메모리 색인의 항목은 압축된 블록의 시작을 가리키게 됨 
    * 압축방식은 디스크 공간을 절약하고 I/O 대역폭 사용도 줄일 수 있음 


### SS테이블 생성과 유지 
위에서 컴팩션과 병합 과정에서 key 를 정렬할 수 있었다. 그렇다면 유입되는 쓰기는 임의 순서대로 발생하는데 key 를 어떻게 정렬할까?  
디스크 상에 정렬된 구조를 유지(뒤에 B트리 참고)하는 일은 가능하지만 메모리에 유지하는 편이 훨씬 쉽다.  
레드 블랙 트리, AVL 트리 처럼 잘 알려진 데이터 구조는 많이 있다. 이런 구조를 이용하면 임의 순서로 키를 삽입하고 정렬된 순서로 키를 다시 읽을 수 있음  
  
이제 저장소 엔진을 다음과 같이 만들수 있다. 
- 쓰기가 발생하면 **인메모리 균형 트리 데이터 구조**에 추가한다.
    * 인 메모리 트리는 **멤테이블(memtable)** 이라고 함 
- 멤테이블이 임계 값 보다 커지면 SS테이블 파일로 디스크에 기록한다.
    * 트리가 이미 키로 정렬되어 있어 디스크 저장을 효율적으로 수행할 수 있음 
    * 새로운 SS테이블 파일은 데이터베이스의 가장 최신 세그먼트가 됨 
    * SS테이블을 디스크에 기록하는 동안 쓰기가 발생하면 새로운 맴테이블에 기록한다.
- 읽기요청이 발생하면 멤테이블에서 먼저 키를 찾고 없으면 최신 세그먼트부터 찾는다. 
- 가끔 병합과 컴팩션 과정을 수행한다. 
    * 이 과정은 백그라운드에서 수행 

### SS 테이블에서 LSM 트리 만들기 
여기에 기술된 알고리즘은 레벨DB(LevelDB)와 록스DB(RocksDB), 다른 애플리케이션에 내장하기 위해 설계된 키-값 저장소 엔진 라이브러리에서 사용한다.  
구글의 빅테이블(Bigtable) 논문에서 **SS테이블과 멤테이블**이라는 용어가 소개되었고 카산드라, HBase 에서도 유사한 저장소 엔진을 사용한다. 
  
이 색인 구조는 LSM 트리(Log-Structured Merge-Tree) 란 이름으로 패트릭 오닐(Patrick O'Neil) 등이 발표했다.  
정렬된 파일 병합과 컴팩션 원리를 기반으로 하는 저장소 엔진을 **LSM 저장소 엔징**이라 부른다. 
  
루씬(Lucene)은 엘라스틱 서치나 솔라에서 사용하는 전문 검색 색인 엔진이다. 루씬은 **용어 사전(term dictionary)** 을 저장하기 위해 유사한 방법을 사용한다.  
검색 질의로 단어가 들어오면 단어가 언급된 모든 문서를 찾는다. 이 방법은 키를 단어(용어)로, 값은 단어를 포함된 모든 문서의 ID 목록으로 하는 키-값 구조로 구현한다.
루씬에서 단어와 문서 ID 목록의 매핑은 SS테이블 같은 정렬 파일에 유지하고 필요에 따라 백그라운드에서 병합한다.  

### 성능 최적화 
LSM 트리 알고리즘은 데이터베이스에 존재하지 않는 키를 찾는 경우 느릴수 있다. 
- 멤테이블을 확인하고 해당 키가 없다는 것을 확인하기 위해 가장 오래된 세그먼트까지 확인하기 때문에 
  
이런 문제를 최적화하기 위해 저장소 엔진은 보통 **블룸 필터(Bloom Filter)** 를 추가적으로 사용한다. 
- 블룸필터는 집합 내용을 근사한 메모리 효율적 데이터 구조
- 블룸필터는 키가 데이터베이스에 존재하지 않음을 알려줌 
  
SS 테이블을 압축하고 병합하는 순서와 시기를 결정하는 다양한 전략이 있다. 가장 일반적인 전략은 **크기 게층(size-tiered)과 레벨 컴팩션(leveled compaction)** 이다.
레벨DB, 록스DB 는 레벨 컴팩션을 사용하고 HBase 는 사이즈 계층을 사용하며 카산드라는 2개 모두 지원한다.  
- 사이즈 계층 컴팩션
    * 이 전략은 아주 큰 SS 테이블을 병합한다. 이런 큰 SS 테이블이 누적되면 더 큰 SS 테이블로 병합한다.
    * 따라서 같은 시작에 다양한 크기에 SS 테이블이 존재하게 된다.
    * 이 전략은 쓰기 집약적은 워크로드에서 적합하지만 데이터를 그룹화하지 않기 때문에 읽는 속도가 느려짐 
    * 가장 큰 SS 테이블의 크기가 커지면 압축 동안 새 SS테이블과 이전 SS 테이블에 동시에 필요한 디스크 공간의 양이 노드와 일반적이 디스크 공간을 초과할 수 있음 
- 레벨 컴팩션
    * level 로 그룹화되는 고정된 작은 크기의 SS테이블을 만든다.
    * SS 테이블은 지속적으로 더 큰 level 로 압축되기 때문에 더 균일하고 예측 가능함 
    * 각 level 의 키는 다음 수준에서 겹치지 않는 SS 테이블로 병합됨 
    * 이 프로세스는 읽기 성능을 향상 시킬 수 있음 

Reference: 
- [카산드라 블로그](https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlHowDataMaintain.html)

  
여러 중요한 세부 사항이 있지만 LSM 트리의 기본 개념은 간단하고 효과적이다.  
- LSM 트리의 기본 개념은 백그라운드에서 연쇄적으로 SS 테이블을 지속적으로 병합하는 것
- 데이터셋이 메모리보다 훨씬 더 크더라도 효과적임 
- 데이터가 정렬된 순서로 저장돼 있다면 범위 질의를 효율적으로 실행할 수 있다.
- 디스크 쓰기는 순차적이기 때문에 매우 높은 쓰기 처리량을 보장함 

## B 트리
- 대부분의 관계형 데이터베이스에서 사용되는 색인 구조 
- 많은 비관계형 데이터에비이스에서도 사용됨 
- B 트리는 정렬된 키-값 쌍을 유지하기 때문에 범위 질의에 효율적임 
- 앞에서 살펴본 로그 구조화 색인은 가변 크기의 세그먼트로 나누고 항상 순차적으로 기록하지만 
- B 트리는 4KB 고정 크기 **블록** 이나 **페이지**로 나누고 한 번에 페이지에 읽기 또는 쓰기를 수행
- 디스크가 고정 크기 블록으로 배열되기 때문에 이런 설계는 하드웨어와 밀접한 관련이 있음 


