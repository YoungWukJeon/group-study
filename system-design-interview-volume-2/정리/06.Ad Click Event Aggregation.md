# 광고 클릭 이벤트 집계(ad click event aggregation)

디지털 광고의 핵심 프로세스는 RTB(Real-Time Bidding)

![06-01](images/06-01.jpg)

- RTB는 프로세스는 속도가 중요해서 보통 1초 내에 모든 프로세스가 마무리되어야 한다.
- 광고주가 얼마나 많은 돈을 지불할지 영향을 끼치기 때문에 데이터의 정확성도 중요하다.
- 온라인 광고에 사용되는 핵심 지표로는 CTR(Click-Through Rate, 클릭률), CTR(Conversion Rate, 전환률) 등이 있으며, 집계된 광고 클릭 데이터에 기반하여 계산한다.

## 1단계: 문제 이해 및 설계 범위 확정
```
지원자: 입력 데이터는 어떤 형태입니까?
면접관: 여러 서버로 분산된 로그 파일입니다. 클릭 이벤트는 수집될 때마다 이 로그 파일의 끝에 추가됩니다. 클릭 이벤트에는 ad_id, click_timestamp, user_id, ip, country 등의 속성이 있습니다. 
지원자: 데이터의 양은 어느 정도입니까?
면접관: 매일 10억 개의 광고 클릭이 발생하고, 광고는 약 2백만 회 게재됩니다. 광고 클릭 이벤트의 수는 매년 30%씩 증가한다고 하겠습니다.
지원자: 가장 중요하게 지원해야 할 질의는 어떤 것입니까?
면접관: 다음의 3가지 질의를 지원해야 합니다.
    - 특정 광고에 대한 지난 M분간의 클릭 이벤트 수
    - 지난 1분간 가장 많이 클릭된 광고 100개. 질의 기간과 광고 수는 변경 가능해야 한다. 집계는 매분 이루어진다.
    - ip, user_id, country 등의 속성을 기준으로 상기 2개 질의 결과를 필터링할 수 있어야 한다.
지원자: 엣지 케이스(edge case)에 대해 걱정해야 하나요? 다음과 같은 경우를 생각해 볼 수 있을 것 같습니다.
    - 예상보다 늦게 도착하는 이벤트가 있을 수 있다.
    - 중복된 이벤트가 있을 수 있다.
    - 시스템 일부가 언제든지 다운될 수 있으므로 시스템 복구를 고려해야 한다.
면접관: 좋네요. 그런 점들을 고려하기로 합시다.
지원자: 지연 시간 요건은 어떻습니까?
면접관: 모든 처리가 수 분 내에 이루어져야 합니다. RTB와 광고 클릭 집계의 지연 시간 요건은 매우 다르다는 점에 유의하세요. RTB 지연 시간은 응답성 요구사항 때문에 일반적으로 1초 미만이어야 하지만, 광고 클릭 이벤트 집계는 주로 광고 과금 및 보고에 사용되기 때문에 몇 분 정ㅈ도의 지연은 허용입니다.
```

### 기능 요구사항
- 지난 M분 동안의 ad_id 클릭 수 집계
- 매분 가장 많이 클릭된 상위 100개 광고 아이디를 반환
- 다양한 속성에 따른 집계 필터링을 지원
- 데이터의 양은 페이스북이나 구글 규모

### 비기능 요구사항
- 집계 결과 정확성 데이터가 RTB 및 광고 과금에 사용되므로 중요
- 지연되거나 중복된 이벤트를 적절히 처리할 수 있어야 함
- 견고성(reliablity): 부분적인 장애는 감내할 수 있어야 함
- 지연 시간 요구사항 : 전체 처리 시간은 최대 수 분을 넘지 않아야 함

### 개략적 추정
- 일간 능동 사용자(DAU) 수는 10억 명(1billion)
- 각 사용자는 하루에 평균 1개 광고를 클릭한다고 가정. 따라서 하루에 10억 건의 광고 클릭 이벤트가 발생
- 광고 클릭 QPS = 10^9 / 하루 10^5 ch = 10,000
- 최대 광고 클릭 QPS는 평균 QPS의 다섯 배, 즉 50,000QPS로 가정
- 광고 클릭 이벤트 하나당 0.1KB의 저장 용량이 필요하다고 가정. 따라서 일일 저장소 요구량은 0.1KB X 10억 = 100GB이며, 월간 저장 용량 요구량은 대략 3TB

## 2단계: 개략적 설계안 제시 및 동의 구하기

### 질의 API 설계
- 본 설계안의 클라이언트는 대시보드를 이용하는 데이터 과학자, 제품 관리자, 광고주 같은 사람이다. 그들이 대시보드를 이용하는 순간 집계 서비스에 질의를 발생한다.
- 요구사항
    - 지난 M분 동안 각 ad_id에 발생한 클릭 수 집계
    - 지난 M분 동안 가장 많은 클릭이 발생한 상위 N개 ad_id 목록 반환
    - 다양한 속성을 기준으로 집계 결과를 필터링하는 기능 지원

#### API 1: 지난 M분간 각 ad_id에 발생한 클릭 수 집계
|API|용도|
|---|---|
|GET /v1/ads/{:ad_id}/aggregated_count|주어진 ad_id에 발생한 이벤트 수를 집계하여 반환|

위 API 호출 인자는 다음과 같다.
|인자명|뜻|자료형|
|---|---|---|
|from|집계 시작 시간 (기본값은 현재 시각부터 1분 전)|long|
|to|집계 종료 시간 (기본값은 현재 시각)|long|
|filter|필터링 전략 식별자. 가령 filter=001는 미국 이외 지역에서 발생한 클릭은 제외하라는 뜻|long|

응답 결과는 다음과 같다.
|필드명|뜻|자료형|
|---|---|---|
|ad_id|광고(ad) 식별자|string|
|count|집계된 클릭 횟수|long|

#### API 2: 지난 M분간 가장 많은 클릭이 발생한 상위 N개 ad_id 목록
|API|용도|
|---|---|
|GET /v1/ads/popular_ads|지난 M분간 가장 많은 클릭이 발생한 상위 N개 광고 목록 반환|

위 API 호출 인자는 다음과 같다.
|인자명|뜻|자료형|
|---|---|---|
|count|상위 몇 개의 광고를 반환할 것인가|integer|
|window|분 단위로 표현된 집계 윈도 크기|integer|
|filter|필터링 전략 식별자|long|

응답 결과는 다음과 같다.
|필드명|뜻|자료형|
|---|---|---|
|ad_ids|광고 식별자 목록|array|

### 데이터 모델

#### 원시 데이터(raw data)
```
[AdClickEvent] ad001, 2021-01-01 00:00:01, user 1, 207.148.22.22, USA
```

|ad_id|click_timestamp|user_id|ip|country|
|---|---|---|---|---|
|ad001|2021-01-01 00:00:01|user1}207.148.22.22|USA|
|ad001|2021-01-01 00:00:02|user1}207.148.22.22|USA|
|ad002|2021-01-01 00:00:02|user2}209.153.56.11|USA|

#### 집계 결과 데이터(aggregated)

|ad_id|click_minute|count|
|---|---|---|
|ad001|202101010000|5|
|ad001|202101010001|7|

광고 필터링을 지원하기 위해 이 테이블에 filter_id를 추가한다.
|ad_id|click_minute|filter_id|count|
|---|---|---|---|
|ad001|202101010000|0012|2|
|ad001|202101010000|0023|3|
|ad001|202101010001|0012|1|
|ad001|202101010001|0023|6|

필터 테이블
|filter_id|region|ip|user_id|
|---|---|---|---|
|0012|US|0012|*|
|0013|*|0012|123.1.2.3|

지난 M분 동안 가장 많이 클릭된 상위 N개의 광고를 반환하는 질의를 지원하기 위해서는 다음과 같은 구조를 사용
||most_clicked_ads||
|---|---|---|
|window_size|integer|분 단위로 표현된 집계 윈도 크기|
|update_time_minute|timestamp|마지막으로 갱신된 타임스탬프(1분 단위)|
|most_clicked_ads|array|JSON 형식으로 표현된 ID 목록|

#### 비교
||원시 데이터만 보관하는 방안|집계 결과 데이터만 보관하는 방법|
|---|---|---|
|장점|- 원본 데이터를 손실 업이 보관<br>- 데이터 필터링 및 재계산 지원|- 데이터 용량 절감<br>- 빠른 질의 성능|
|단점|- 막대한 데이터 용량<br>- 낮은 질의 성능|- 데이터 손실. 원본 데이터가 아닌 계산/유도된 데이터를 저장하는 데서 오는 결과. 예를 들어 10개의 원본 데이터는 1개의 데이터로 집계/축약될 수 있다.|

원시 데이터와 집계 결과 데이터를 모두 저장하는 것을 추천한다.
- 문제가 발생하면 디버깅에 활용할 수 있도록 원시 데이터도 보관하는 것이 좋다. (버그로 집계 데이터가 손상되면 버그 수정 후에 원시 데이터에서 집계 결과를 다시 만들 수 있다.)
- 원시 데이터는 양이 엄청나므로 직접 질의하는 것은 비효율적이다. 이 문제를 완화하려면 집계 결과 데이터를 질의하는 것이 바람직하다.
- 원시 데이터는 백업 데이터로 활용된다. 재계산을 하는 경우가 아니라면 일반적으로는 원시 데이터를 질의할 필요가 없다. 오래된 원시 데이터는 냉동 저장소(cold storage)로 옮기면 비용을 절감할 수 있다.
- 집계 결과 데이터는 활성 데이터(active data) 구실을 한다. 질의 성능을 높이기 위해 튜닝을 하는 것이 보통이다.

### 올바른 데이터베이스의 선택


### 개략적 설계안

#### 비동기 처리






















