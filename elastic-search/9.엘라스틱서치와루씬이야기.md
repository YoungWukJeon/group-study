## 클러스터 관점에서 구성요소

- 엘라스틱서치는 기본적으로 클러스터라는 단위로 데이터를 제공

#### 클러스터
- 클러스터(Cluster)는 데이터를 실제로 가지고 있는 노드의 모임
- 관련된 모든 노드들을 논리적으로 확장해서 클러스터라고 부름
- 같은 클러스터 내부의 데이터만 서로 공유가 가능
- Cross Cluster Search
    - 다수의 클러스터의 데이터를 한 번에 검색하는 것이 가능
    - 과거의 트라이브 노드(Tribe Node)라는 형태의 대체제(deprecated 예정)

#### 노드
- 실행 시 노드는 클러스터에 의해 UUID(Universally Unique IDentifier)가 할당됨
- 직접 이름을 설정 가능
- 노드는 내부에 다수의 인덱스를 가짐
- 각 인덱스는 다수의 문서를 가짐
- 모든 노드는 마스터 노드와 데이터 노드의 역할을 동시에 수행할 수 있도록 설정됨
- 실제 운영 시에는 역할에 따라 노드를 물리적으로 분리하는 것이 좋다.

#### 인덱스
- 엘라스틱서치 인덱스(Index)는 유사한 특성을 가지고 있는 문서를 모아둔 문서들의 컬렉션
- 인덱스명은 모두 소문자로 설정해야함
- 루씬 인덱스
    - 루씬에서는 전문을 분석하고 분석한 결과를 물리적인 디스크에 저장하는 인덱싱이라는 과정이 있다.
    - 이 과정에서 생성된 데이터를 인덱스(Index)라고 부름
    - 엘라스틱서치의 인덱스와는 다름

#### 문서
- 검색 대상이 되는 실제 물리적인 데이터
- 엘라스틱서치에서는 JSON 형식으로 표현
- 실제로는 물리적인 샤드 형태로 나눠져서 다수의 노드로 분산 저장

#### 샤드
- 데이터를 분산 저장하는 방식으로 손쉬운 수평 확장이 가능해진다.
- 샤드는 인덱스의 전체 데이터를 분산해서 가지고 있는 일종의 부분집합
- 각 샤드는 자신이 가지고 있는 데이터만으로도 독립적으로 검색 서비스가 가능
- 실제로 인덱스에 쿼리를 요청하면 인덱스가 가지고 있는 모든 샤드로 검색 요청이 전달되고 각 샤드에서 1차적으로 검색이 어루어진 후 그 결과를 취합해서 최종 결과를 제공

#### 레플리카
- 샤드의 복제본
- 엘라스틱서치에서는 레플리카를 이용한 페일오버 메커니즘을 제공
- 엘라스틱서치의 고가용성
    - 검색 시 샤드와 레플리카에서 병렬로 실행될 수 있기 때문에 검색 성능이 좋아지는 결과를 가져온다.

#### 세그먼트
- 엘라스틱서치는 루씬 라이브러리를 통해 대부분의 검색 기능을 제공
- 루씬에 데이터가 색인되면 데이터는 최소한의 단위인 토큰으로 분리되고 특수한 형태의 자료구조로 저장
- 이 자료구조를 세그먼트(Segment)라고 함
- 세그먼트는 읽기에 최적화된 자료구조로서 역색인이라는 특수한 형태로 변환되어 물리적인 디스크에 저장된다.

## 엘라스틱서치 샤드 vs 루씬 인덱스

- 루씬에서 IndexWriter는 데이터를 색인하는 클래스
- 루씬에서 IndexSearcher는 색인된 데이터를 검색 결과로 제공하는 클래스
- IndexWriter와 IndexSearcher를 가지고 색인과 검색을 동시에 제공하는 루씬 인스턴스를 루씬 인덱스라고 함
- 엘라스틱서치 인덱스는 물리적으로 분산된 엑라스틱서치 샤드를 논리적인 관점에서 하나의 거대한 데이터로 바라보는 것
- 루씬 인덱스는 세그먼트를 이용해 검색을 수행
- 하나의 샤드는 자체적으로 데이터를 색인하고 검색할 수 있는 가장 작은 크기의 단일 검색엔진
- 루씬 인덱스가 자기 자신이 가지고 있는 세그먼트 내에서만 검색이 가능
- 엘라스틱서치 샤드는 모든 샤드가 가지고 있는 세그먼트들을 논리적으로 통합해서 검색 가능
- 엘라스틱서치 샤드는 다수의 인스턴스 간에 데이터를 분산 저장할 수 있는 근간이 되고, 이를 통해 분산 클러스터를 구축하는 것이 가능

## 엘라스틱서치가 근실시간 검색을 제공하는 이유

#### 색인 작업 시 세그먼트의 기본 동작 방식
- 하나의 루씬 인덱스는 내부적으로 다수의 세그먼트로 구성돼 있다.
- 루씬은 검색 요청을 받으면 다수의 작은 세그먼트 조각들이 각각 검색 결과 조각을 만들어 내고 이를 통합해서 하나의 결과로 합쳐서 응답하도록 설계돼 있다.
- 세그먼트는 역색인 구조를 지닌 파일 자체를 의미
- 루씬에는 세그먼트들을 관리하기 위한 용도로 커밋 포인트(Commit Point)라는 자료구조를 제공
- 커밋 포인트는 여러 세그먼트의 목록 정보를 가지고 있다.
- 검색 요청 시 커밋 포인트를 이용해 가장 오래된 세그먼트부터 차례대로 검색한 후 각 결과를 하나로 합쳐서 제공
- 검색 작업을 요청 시 IndexSearcher가 커밋 포인트를 이용해 모든 세그먼트를 읽어 검색 결과를 제공
- 색인 작업이 일어날 때마다 이런 식으로 세그먼트의 개수가 점점 늘어난다.
- 세그먼트가 많아지면 읽기 성능이 저하될 수 있기 때문에 루씬에서는 백그라운드에서 주기적으로 세그먼트 파일을 Merge(병합)하는 작업을 수행하고 이를 통해 모든 세그먼트들을 물리적으로 하나의 파일로 병합
- 루씬은 색인 작업 시 기존에 생성된 세그먼트에는 정보를 추가하거나 변경하지 않고 색인 작업을 할 때마다 새로운 세그먼트 파일이 생성된다.
- 주기적인 Merge 작업에 의해 세그먼트가 통합되고 삭제되기 전까지는 전혀 수정을 허용하지 않는다.

#### 세그먼트 불변성
- 루씬에서 수정을 허용하지 않는 세그먼트의 이러한 동작 방식을 불변성(Immutablity)이라고 부른다.
- 장점
    - 동시성 문제를 회피할 수 있다. (Lock이 불필요)
    - 시스템 캐시를 적극적으로 활용할 수 있다.
    - 높은 캐시 적중률을 유지할 수 있다.
    - 리소스를 절감할 수 있다.
- 단점
    - 일부 데이터가 변경되더라도 전체 역색인 구조를 다시 만들어야 한다.
    - 실시간 반영이 상대적으로 어려워진다.

#### 세그먼트 불변성과 업데이트
- 수정 연산이지만 내부적으로는 삭제 후 추가하는 방식을 사용함으로써 불변성을 지키면서도 검색엔진에 수정 기능을 부여할 수 있는 것
- 삭제 연산도 단순히 데이트를 삭제하는 것이 아니라, 모든 문서에 삭제 여부를 표시하는 비트 배열이 내부적으로 존재하고, 삭제 요청이 들어오면 삭제될 대상 데이터의 비트 배열을 찾아 삭제 여부만 표시
- 비트 배열에 삭제 여부만 표시했기 때문에 실제 데이터는 여전히 세그먼트 내부에 물리적으로 남아 있다.
- 실제 물리적으로 데이터가 삭제되늰 시점은 백그라운드에서 주기적으로 일어나는 Merge 작업이 수행될 때다.
- 문서 하나를 삭제하려면 전체 여객인 구조를 뒤져서 관련된 모든 텀을 제거해야 하기 때문에 세그먼트를 다시 생성하는 것과 별반 다를 바가 없어진다.

#### 루씬을 위한 Flush, Commit, Merge
- 루씬은 효율적인 색인 작업을 위해 내부적으로 일정 크기의 버퍼(In-memory buffer)를 가짐
- 버퍼가 없다면 
    - 데이터가 들어올 때마다 동기적으로 작업을 수행해야 하기 때문에 데이터를 유실하지 않을면 요청할 때마다 매번 세그먼트를 만들어야 한다.
    - 대량의 데이터가 빠르게 요청될 경우 지연이 발생할 수 밖에 없고 이는 곧 서비스의 장애로 이어진다.
- 인메모리 버퍼는 색인 작업이 요청되면 전달된 데이터를 순서대로 저장해서 일종의 큐(Queue)로 활용한다.
- 버퍼에 모여 한번에 처리된 데이터는 세그먼트 형태로 생성되고 즉시 디스크로 동기화된다.
- 새로운 세그먼트가 생성되고 디스크에 동기화하는 과정까지 거쳐야만 비로소 검색이 가능해진다.
- 세그먼트가 생성될 때마다 물리적인 동기화를 할 경우 성능이 급격히 나빠질 수 있다.
- 루씬은 이러한 문제를 해결하기 위해 무거운 fsync 방식을 이용해 디스크 동기화를 하는 대신 상대적으로 가벼운 write 방식을 이용해 쓰기 과정을 수행한다. 이 과정을 루씬에서는 Flush라고 한다.
- 일단 Flush 처리에 의해 세그먼트가 생성되면 커널 시스템 캐시에 세그먼트가 캐시되어 읽기가 가능해진다.
- write() 함수
    - 파일을 저장할 때 사용하는 함수
    - 시스템 캐시에만 기록되고 리턴된다.
- fsync() 함수
    - 저수준의 파일 입출력 함수
    - 내부 시스템 캐시의 데이터와 물리적인 디스크의 데이터를 동기화하기 위한 목적으로 사용
- 루씬이 디스크 동기화를 위해 write() 함수를 이용하기 때문에 디스크에 물리적으로 기록되는 것이 100% 보장되지 않는다.
- 루씬에서는 물리적으로 디스크에 기록을 수행하는 fsync() 함수를 호출하는 작업을 Commit이라고 한다.
- Merge 작업의 장점
    - 검색 성능이 좋아진다. (세그먼트 수 감소)
    - 세크먼트가 차지하는 디스크의 용량이 줄어든다.
- Merge 작업의 단점
    - Commit 작업을 반드시 동반하기 때문에 실행하는데 많은 리소스가 필요하기 때문에 정책적으로 적절한 주기를 설정하는 것이 매우 중요하다.

#### 엘라스틱서치를 위한 Refresh, Flush, Optimize API
- Refresh
    - 엘라스틱서치에서는 클러스터에 조재하는 모든 샤드에서 기본적으로 1초마다 한 번씩 루씬의 Flush 작업을 수행하는데 이를 Refresh 작업이라고 한다.
- Flush
    - 엘라스틱서치에서 Flush는 루씬의 Commit 작업을 수행하고 새로운 Translog를 시작한다는 의미다.
    - Translog는 엘라스틱서치에만 존재하는 개념으로, 엘라스틱서치가 제공하는 고가용성과 매우 밀접한 관련이 있다.
    - Translog는 샤드의 장애 복구를 위해 제공되는 특수한 파일이다.
    - 샤드는 자신에게 일어나는 모든 변경사항을 Translog에 먼저 기록한 후 내부에 존재하는 루씬을 호출한다.
    - 샤드는 1초마다 Refresh 작업을 수행해서 실시간에 가까운 검색을 제공한다.
    - 엘라스틱서치에서는 기본적으로 5초에 한번씩 Flush 작업이 수행된다.
- Optimize API
    - 엘라스틱서치는 인덱스 최적화를 위해 Optimize API를 제공한다.
    - force merge API라고도 한다.
    - 루씬 Merge 작업을 강제로 수행하는 기능이다.
    - ex) POST /movie/_forcemerge?max_num_segments=1

#### 엘라스틱서치와 NRT(Near Real-Time)
- 엘라스틱서치 샤드는 루씬의 기능을 확정해서 제공한다.
- 샤드는 한마디로 '장애 복구 기능을 가진 작은 루씬 기반의 단일 엔진 서버'
- 엘라스틱서치 인덱스를 검색하면 인덱스에 포함된 모든 샤드(루씬 인덱스)로 동시에 요청이 보내진다.
- 요청을 받은 각 샤드에서는 커밋 포인트를 이용해 내부에 존재하는 모든 세그먼트들을 순서대로 검색한 후 결과를 전달
- 엘라스틱서치는 모든 샤드로부터 검색 결과가 도착할 때까지 기다린다.
- 모든 샤드로부터 검색 결과가 도착하면 하나의 커다란 결과 셋을 만들게  되고 이 결과 셋을 최종적으로 사용자에게 전달

## 고가용성을 위한 Translog의 비밀

- 엘라스틱서치는 분산 시스템이 지원해야 하는 고가용성을 제공하기 위해 내부적으로 Translog라는 특수한 형태의 파일을 유지하고 관리하고 있다.
- 장애 복구를 위한 백업 데이터 및 데이터 유실 방지를 위한 저장소로써 Translog를 적극 활용하고 있다.

#### Translog의 동작 순서
- 엘라스틱서치 샤드는 내부에 Translog라는 특수한 파일을 가지고 있다.
- 샤드에 어떠한 변경사항이 생길 경우 Translog 파일에 먼저 해당 내역을 기록한 후 내부에 존재하는 루씬 인덱스로 데이터를 전달
- 전달된 데이터는 인메모리 버퍼로 저장되고 주기적으로 처리되어 결과적으로 세그먼트가 된다.
- 엘라스틱서치는 기본적으로 1초에 한번씩 Refresh 작업이 수행되는데, Refresh 작업이 일어나더라도 Translog 파일에 기록된 내용은 삭제되지 않고 계속 유지된다.
- 특정 시점이 되면 Translog 내부의 로그 중 불필요한 과거의 로그는 삭제된다.
- Flush 작업이 성공적으로 마무리되고 물리적으로 디스크 동기화에 성공하면 누적돼 있던 Translog 파일의 내용이 비로소 삭제된다.

#### Translog가 존재하는 이유
- 가장 큰 목적은 장애 복구를 위해서다.
- Translog의 주목적은 클러스터를 운영하는 중에 데이터가 손실되지 않도록 보장하는 것이다.
- 운영 중에 샤드에 크래시가 발생할 경우에도 Translog를 이용한다.

## 엘라스틱서치 샤드 최적화

#### 운영 중에 샤드의 개수를 수정하지 못하는 이유
- 엘라스틱서치 샤드에는 실제 서비스가 일어나는 프라이머리 샤드와 장애 복구를 위해 존재하는 레플리카 샤드가 존재한다.
- 레플리카 샤드는 또한 프라이머리 샤드와 동일한 데이터를 가지고 있기 때문에 평상시에는 읽기 분산에 활용된다.
- 샤드 내부의 루씬 입장에서는 함께 인덱스를 구성하는 다른 샤드의 존재를 전혀 눈치채지 못한다.
- 운영 중인 프라이머리 샤드의 수가 증가된다면 기존에 존재하던 프라이머리 샤드들의 일부 세그먼트들이 새롭게 추가된 프라이머리 샤드 쪽으로 분산되어야 한다.
- 이 작업은 기존의 세그먼트들이 새롭게 변경되어야 함을 의미한다.
- 세그먼트의 변경은 원칙적으로 불가능하다. (세그먼트 불변성)
- 이러한 이유로 현재는 프라이머리 샤드의 개수를 변경할 방법이 없다.
- ReIndex API
    - 현재로서는 샤드의 개수를 변경하기 위해서는 인덱스를 새롭게 생성하고 전체 데이터를 처음부터 다시 재색인하는 방법밖에 없다.

#### 레플리카 샤드의 복제본 수는 얼마가 적당할까?
- 레플리카 세트의 수를 결정할 경우에는 사전에 충분한 테스트가 필요한데, 너무 많은 복제본이 존재할 경우에는 자칫 전체적인 색인 성능의 저하로 이어질 수 있다.
- 엘라스틱서체에 데이터가 추가되면 마스터 노드에 의해 적절히 라우팅되어 특정 프라이머리 샤드로 데이터가 전송된다.
- 레플리카도 동일한 검색 결과를 보장해야 하기 때문에 존재하는 모든 레플리카 샤드에도 데이터가 전송된다.

#### 클러스터에서 운영 가능한 최대 샤드 수는?
- 개별 인덱스를 생성할 때 설정 가능한 샤드의 수는 현재 1024개로 제한돼 있다.
- 클러스터에 많은 수의 샤드가 존재할 경우
    - 클러스터에 존재하는 모든 샤드는 마스터 노드에서 관리된다.
    - 마스터 노드는 빠른 처리를 위해 샤드 정보와 같은 관리 데이터를 모두 메모리에 올려서 제공
    - 샤드의 수가 많아지면 마스터 노드에 부하가 커지며, 마스터 노드에 장애가 발생한다면 클러스터 전체가 마비된다.
- 인덱스가 다수의 샤드로 분산될 경우
    - 단순히 검색 성능만 놓고 본다면 인덱스를 생성할 때 프라이머리 샤드의 개수가 많을수록 검색 성능이 좋아진다.
- 샤드의 물리적인 크기와 복구 시간
    - 일단 노드에 장애가 발생하면 장애가 발생한 프라이머리 샤드와 동일한 데이터를 가지고 있는 레플리카 샤드가 순간적으로 프라이머리 샤드로 전환되어 서비스된다.
    - 그와 동시에 프라이머리 샤드로 전환된 샤드와 동일한 샤드가 물리적으로 다른 장비에서 레플리카 샤드로 새롭게 생성된다.
    - 시간이 지나 장애가 발생한 노드가 복구되면 복구된 노드로 일부 샤드들이 네트워크를 통해 이동한다.
    - 복구 시 샤드 단위로 데이터가 이동하기 때문에 샤드의 크기가 클수록 복구 작업에 부정적인 영향을 끼친다.
- 적절한 샤드의 크기
    - 샤드 1개가 물리적으로 50GB를 넘지 않도록 권장하고 있다.

#### 하나의 인덱스에 생성 가능한 최대 문서의 수는?
- 최신 버전(책 ES 6.4.3 기준)에서 1024개라는 제약을 두고 있는데 이는 극단적으로 많은 수의 샤드를 생성할 경우 마스터 노드에 상당한 부하가 걸리기 때문에 마스터 노드 보호 차원에서 최소한의 제약을 만든 것이다.
- 하나의 샤드에서 색인할 수 있는 문서 수가 대략적으로 20억(2^31 - 128) 개 정도